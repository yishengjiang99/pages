<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Audio Piano Roll</title>
<style>
  body { margin: 0; overflow: hidden; font-family: sans-serif; user-select: none; -webkit-user-select: none; touch-action: manipulation; }
  #controls { display: flex; flex-wrap: wrap; gap: 8px; padding: 8px; background: #222; color: #fff; align-items: center; }
  button, input[type=range] { font-size: 18px; padding: 10px; border-radius: 6px; border: none; }
  button { background: #4CAF50; color: white; }
  .volumeContainer, .noiseGateContainer { display: flex; flex-direction: column; align-items: flex-start; margin-left: 8px; }
  #volume { width: 150px; height: 20px; background: #555; position: relative; }
  #volumeLevel { height: 100%; width: 0%; background: lime; }
  #volumeText { font-size: 12px; color: #fff; margin-top: 2px; }
  #noiseGateSlider { width: 150px; }
  #pianoContainer { display: flex; height: 600px; overflow: hidden; border-top: 1px solid #ccc; }
  #pianoAxis { width: 60px; background: #eee; border-right: 1px solid #ccc; }
  #pianoAxis svg { width: 60px; height: 100%; display: block; }
  #pianoRollWrapper { flex: 1; overflow-x: scroll; overflow-y: hidden; background: #111; }
  #pianoRoll { height: 600px; }
  #log { height: 120px; overflow-y: scroll; background: #000; color: #0f0; padding: 4px; font-size: 12px; white-space: pre-wrap; }
</style>
</head>
<body>
<div id="controls">
  <button id="startBtn">Start</button>
  <button id="stopBtn">Stop</button>
  <button id="exportBtn">Export MIDI</button>

  <div class="volumeContainer">
    <label>Volume:</label>
    <div id="volume"><div id="volumeLevel"></div></div>
    <div id="volumeText">0.00</div>
  </div>

  <div class="noiseGateContainer">
    <label for="noiseGateSlider">Noise Gate Threshold:</label>
    <input type="range" id="noiseGateSlider" min="0" max="0.1" step="0.001" value="0.02">
    <div id="noiseGateValue">0.02</div>
  </div>

  <input id="timeSlider" type="range" min="0" max="60" value="0" step="1">
</div>

<div id="pianoContainer">
  <div id="pianoAxis">
    <svg id="axisSvg" xmlns="http://www.w3.org/2000/svg"></svg>
  </div>
  <div id="pianoRollWrapper">
    <svg id="pianoRoll" xmlns="http://www.w3.org/2000/svg"></svg>
  </div>
</div>

<pre id="log"></pre>

<script>
const logEl = document.getElementById("log");
const volumeLevel = document.getElementById("volumeLevel");
const volumeText = document.getElementById("volumeText");
const noiseGateSlider = document.getElementById("noiseGateSlider");
const noiseGateValue = document.getElementById("noiseGateValue");

function log(msg){ logEl.textContent += msg + "\n"; logEl.scrollTop = logEl.scrollHeight; }

// Catch all JS errors
window.addEventListener("error", e => log("JS Error: " + e.message + " @ " + e.filename + ":" + e.lineno));
window.addEventListener("unhandledrejection", e => log("Unhandled Promise Rejection: " + e.reason));

let audioContext, mic, analyser, highpass, workletNode;
let running = false;
let capturedNotes = [];
let noteState = new Map();
let startTime = 0;
const roll = document.getElementById("pianoRoll");
const timeSlider = document.getElementById("timeSlider");

const minMidi = 40, maxMidi = 84;
const keyHeight = 12;
const widthPerSec = 100;
let noiseThreshold = parseFloat(noiseGateSlider.value);

noiseGateSlider.oninput = () => {
  noiseThreshold = parseFloat(noiseGateSlider.value);
  noiseGateValue.textContent = noiseThreshold.toFixed(3);
  if(workletNode) workletNode.port.postMessage({type:"threshold",value:noiseThreshold});
};

// Piano axis drawing
function drawAxis(){
  const NS = "http://www.w3.org/2000/svg";
  const axisSvg = document.getElementById("axisSvg");
  axisSvg.innerHTML = "";
  axisSvg.setAttribute("height",(maxMidi-minMidi+1)*keyHeight);
  for(let m=maxMidi; m>=minMidi; m--){
    const y = (maxMidi-m)*keyHeight;
    const rect = document.createElementNS(NS,"rect");
    rect.setAttribute("x",0); rect.setAttribute("y",y);
    rect.setAttribute("width",60); rect.setAttribute("height",keyHeight);
    rect.setAttribute("fill", [1,3,6,8,10].includes(m%12)?"#333":"#fff");
    rect.setAttribute("stroke","#000");
    axisSvg.appendChild(rect);
    if(![1,3,6,8,10].includes(m%12)){
      const text = document.createElementNS(NS,"text");
      text.setAttribute("x",5); text.setAttribute("y",y+keyHeight-2);
      text.setAttribute("font-size","10");
      text.textContent = ["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"][m%12]+Math.floor(m/12);
      axisSvg.appendChild(text);
    }
  }
}

// Piano roll drawing
function drawPianoRoll(){
  roll.innerHTML="";
  const NS="http://www.w3.org/2000/svg";
  const totalW = (parseFloat(timeSlider.max)||1)*widthPerSec + 200;
  const totalH = (maxMidi-minMidi+1)*keyHeight;
  roll.setAttribute("width",totalW);
  roll.setAttribute("height",totalH);

  let notes=[...capturedNotes];
  if(running){ for(let [m,st] of noteState){ notes.push({midi:m,start:st.start,end:audioContext.currentTime}); } }

  for(let ev of notes){
    if(!ev.end||ev.end<=ev.start) continue;
    const x = ev.start*widthPerSec;
    const w = (ev.end-ev.start)*widthPerSec;
    const y = (maxMidi-ev.midi)*keyHeight;
    const rect = document.createElementNS(NS,"rect");
    rect.setAttribute("x",x);
    rect.setAttribute("y",y);
    rect.setAttribute("width",w);
    rect.setAttribute("height",keyHeight-1);
    rect.setAttribute("fill","#4CAF50");
    roll.appendChild(rect);
  }
}

// Audio Worklet setup
async function setup(){
  const workletCode = `
    let threshold=${noiseThreshold};
    class FFTProcessor extends AudioWorkletProcessor{
      constructor(){super();this.buf=new Float32Array(2048);this.i=0;this.hpBuf=0;this.alpha=2*Math.PI*70/sampleRate;this.port.postMessage({type:"ready"});}
      process(inputs){let input=inputs[0];if(!input||!input[0])return true;let ch=input[0];for(let s of ch){this.hpBuf+=this.alpha*(s-this.hpBuf);let x=this.hpBuf;if(Math.abs(x)>threshold){this.buf[this.i++]=x;if(this.i>=this.buf.length){let fftSize=this.buf.length;let re=new Float32Array(fftSize),im=new Float32Array(fftSize);for(let j=0;j<fftSize;j++){re[j]=this.buf[j];im[j]=0;}for(let step=1;step<fftSize;step<<=1){let jump=step<<1;for(let grp=0;grp<step;grp++){let ang=-Math.PI*grp/step;let wr=Math.cos(ang),wi=Math.sin(ang);for(let k=grp;k<fftSize;k+=jump){let l=k+step;let tr=wr*re[l]-wi*im[l];let ti=wr*im[l]+wi*re[l];re[l]=re[k]-tr;im[l]=im[k]-ti;re[k]+=tr;im[k]+=ti;}}}let mags=new Float32Array(fftSize/2);for(let j=0;j<mags.length;j++)mags[j]=Math.sqrt(re[j]*re[j]+im[j]*im[j]);let peaks=[];for(let j=1;j<mags.length-1;j++){if(mags[j]>mags[j-1]&&mags[j]>mags[j+1]&&mags[j]>50){let freq=j*sampleRate/fftSize;let midi=Math.round(69+12*Math.log2(freq/440));peaks.push(midi);}}if(peaks.length)this.port.postMessage({type:"notes",notes:peaks,time=currentTime});this.i=0;}}}return true;}
    }
    registerProcessor("fft-processor",FFTProcessor);
    this.port.onmessage = e => { if(e.data.type==="threshold") threshold=e.data.value; };
  `;
  const blob = new Blob([workletCode], { type: 'text/javascript' });
  const moduleURL = URL.createObjectURL(blob);
  await audioContext.audioWorklet.addModule(moduleURL);
  URL.revokeObjectURL(moduleURL);

  mic=await navigator.mediaDevices.getUserMedia({audio:true});
  highpass=audioContext.createBiquadFilter();
  highpass.type="highpass";highpass.frequency.value=70;
  analyser=audioContext.createAnalyser();
  workletNode=new AudioWorkletNode(audioContext,"fft-processor");
  const source=audioContext.createMediaStreamSource(mic);
  source.connect(highpass).connect(workletNode).connect(analyser);

  workletNode.port.onmessage = e => {
    let msg = e.data;
    if(msg.type==="ready") log("Worklet ready");
    if(msg.type==="notes"&&running) handleNotes(msg.notes,msg.time);
  };

  visualizeVolume();
}

// Volume Meter
function visualizeVolume(){
  const data=new Uint8Array(analyser.fftSize);
  function draw(){
    requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(data);
    let sum=0;for(let v of data){let d=v-128;sum+=d*d;}
    let rms=Math.sqrt(sum/data.length)/128;
    volumeLevel.style.width = (rms*100)+"%";
    volumeText.textContent = rms.toFixed(2);
  }
  draw();
}

// Note Handling
function handleNotes(notes,time){
  for(let m of notes){
    if(!noteState.has(m)){ noteState.set(m,{start:time}); log("NoteOn "+m); }
  }
  for(let [m,st] of [...noteState]){
    if(!notes.includes(m)){ capturedNotes.push({midi:m,start:st.start,end:time}); noteState.delete(m); log("NoteOff "+m); }
  }
  drawPianoRoll();
}

// Buttons
document.getElementById("startBtn").onclick = async () => {
  try {
    if (!audioContext) { audioContext = new AudioContext(); await audioContext.resume(); await setup(); }
    else if (audioContext.state==="suspended") await audioContext.resume();
    running=true; startTime=audioContext.currentTime; log("Recording started");
  } catch(e){ log("StartBtn Error: "+e.message); }
};
document.getElementById("stopBtn").onclick = () => {
  try { if(audioContext && audioContext.state==="running") audioContext.suspend(); running=false; log("Stopped"); drawPianoRoll(); }
  catch(e){ log("StopBtn Error: "+e.message); }
};
document.getElementById("exportBtn").onclick = () => { try { exportMIDI(); } catch(e){ log("ExportBtn Error: "+e.message); } };

// MIDI Export
function exportMIDI(){ /* implement MIDI export as before */ }

drawAxis();
</script>
</body>
</html>