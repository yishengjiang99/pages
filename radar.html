<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sound Source Localization</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 1rem;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #f5f5f5;
            min-height: 100vh;
            box-sizing: border-box;
        }
        canvas {
            max-width: 100%;
            height: auto;
            border: 1px solid #ccc;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        p {
            text-align: center;
            max-width: 90%;
            line-height: 1.4;
            color: #666;
            font-size: 0.9rem;
        }
        .controls {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.5rem;
            width: 100%;
            max-width: 300px;
            margin-top: 1rem;
        }
        .mic-group {
            display: flex;
            flex-direction: column;
            width: 100%;
            gap: 0.25rem;
        }
        label {
            font-weight: 600;
            color: #333;
            align-self: flex-start;
            font-size: 0.9rem;
        }
        select {
            width: 100%;
            padding: 8px 12px;
            border: 1px solid #ccc;
            border-radius: 6px;
            background-color: white;
            font-size: 1rem;
        }
        button {
            background-color: #007aff;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            width: 100%;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        button:hover {
            background-color: #0056cc;
        }
        button:active {
            transform: scale(0.98);
        }
        .secondary-btn {
            background-color: #6c757d;
        }
        .secondary-btn:hover {
            background-color: #545b62;
        }
        @media (max-width: 480px) {
            body {
                padding: 0.5rem;
            }
            p {
                font-size: 0.8rem;
            }
            button {
                padding: 14px 20px;
                font-size: 1.1rem;
            }
        }
    </style>
</head>
<body>
    <canvas id="canvas" width="400" height="400"></canvas>
    <p>Drag the microphone icons (L and R) on the canvas to position them relative to your head (top-down view). The inter-microphone distance will be used for localization. Select two microphones for left and right channels. This assumes mono input from each; they will be merged into stereo for processing. In practice, test with your setup. Processing uses frequency-domain correlation via custom FFT implementation. Updated for iOS Safari compatibility: dynamic biquad coefficients based on sample rate, omitted fixed sample rate in AudioContext. Added left/right RMS computation and scrolling line chart display in bottom of canvas.</p>
    <div class="controls">
        <div class="mic-group">
            <label for="micLeft">Left Microphone:</label>
            <select id="micLeft">
                <option value="">Select...</option>
            </select>
        </div>
        <div class="mic-group">
            <label for="micRight">Right Microphone:</label>
            <select id="micRight">
                <option value="">Select...</option>
            </select>
        </div>
        <button class="secondary-btn" onclick="detectMicrophones()">Detect Microphones</button>
        <button onclick="start()">Start Listening</button>
    </div>
    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let angle = 0;
        let leftHistory = [];
        let rightHistory = [];
        const maxHistory = 400;
        let chartHeight;
        let chartY;
        let audioDevices = [];
        let audioContext;
        let processor;
        let draggingMic = null;
        const micRadius = 5;
        const hitRadius = 10;
        const mics = [
            {id: 'left', x: -50, y: 0, label: 'L'},
            {id: 'right', x: 50, y: 0, label: 'R'}
        ];
        const pixelToMeterScale = 0.17 / 100;  // 100px initial distance = 0.17m

        // Make canvas responsive
        function resizeCanvas() {
            const dpr = window.devicePixelRatio || 1;
            const rect = canvas.getBoundingClientRect();
            canvas.width = rect.width * dpr;
            canvas.height = rect.height * dpr;
            ctx.scale(dpr, dpr);
            draw();
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();  // Initial resize

        function getMousePos(e) {
            const rect = canvas.getBoundingClientRect();
            return {
                x: e.clientX - rect.left,
                y: e.clientY - rect.top
            };
        }

        function updateMicDistance() {
            const dx = mics[0].x - mics[1].x;
            const dy = mics[0].y - mics[1].y;
            const pixelDist = Math.sqrt(dx * dx + dy * dy);
            const newD = pixelDist * pixelToMeterScale;
            if (processor && processor.port) {
                processor.port.postMessage({ type: 'update-d', d: newD });
            }
        }

        canvas.addEventListener('mousedown', (e) => {
            e.preventDefault();
            const pos = getMousePos(e);
            const width = canvas.width / (window.devicePixelRatio || 1);
            const height = canvas.height / (window.devicePixelRatio || 1);
            const headCenterX = width / 2;
            const headCenterY = height * 0.3;
            const relX = pos.x - headCenterX;
            const relY = pos.y - headCenterY;
            for (let mic of mics) {
                const dx = relX - mic.x;
                const dy = relY - mic.y;
                if (dx * dx + dy * dy < hitRadius * hitRadius) {
                    draggingMic = mic;
                    break;
                }
            }
        });

        canvas.addEventListener('mousemove', (e) => {
            if (draggingMic) {
                e.preventDefault();
                const pos = getMousePos(e);
                const width = canvas.width / (window.devicePixelRatio || 1);
                const height = canvas.height / (window.devicePixelRatio || 1);
                const headCenterX = width / 2;
                const headCenterY = height * 0.3;
                draggingMic.x = pos.x - headCenterX;
                draggingMic.y = pos.y - headCenterY;
                updateMicDistance();
                draw();
            }
        });

        canvas.addEventListener('mouseup', (e) => {
            e.preventDefault();
            draggingMic = null;
        });

        canvas.addEventListener('mouseleave', (e) => {
            draggingMic = null;
        });

        async function detectMicrophones() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const devices = await navigator.mediaDevices.enumerateDevices();
                audioDevices = devices.filter(device => device.kind === 'audioinput');
                const leftSelect = document.getElementById('micLeft');
                const rightSelect = document.getElementById('micRight');
                leftSelect.innerHTML = '<option value="">Select...</option>';
                rightSelect.innerHTML = '<option value="">Select...</option>';
                audioDevices.forEach((device, index) => {
                    const optionLeft = new Option(device.label || `Microphone ${index + 1}`, device.deviceId);
                    const optionRight = new Option(device.label || `Microphone ${index + 1}`, device.deviceId);
                    leftSelect.add(optionLeft);
                    rightSelect.add(optionRight);
                });
                stream.getTracks().forEach(track => track.stop());
            } catch (error) {
                console.error('Error accessing devices:', error);
                alert('Failed to access microphones. Ensure permissions are granted.');
            }
        }

        async function getMicStream(deviceId) {
            const constraints = {
                audio: {
                    deviceId: { exact: deviceId },
                    channelCount: { ideal: 1 },
                    echoCancellation: false,
                    noiseSuppression: false
                }
            };
            return await navigator.mediaDevices.getUserMedia(constraints);
        }

        async function start() {
            try {
                const leftSelect = document.getElementById('micLeft');
                const rightSelect = document.getElementById('micRight');
                const leftId = leftSelect.value;
                const rightId = rightSelect.value;
                if (!leftId || !rightId) {
                    alert('Please select both left and right microphones.');
                    return;
                }
                if (leftId === rightId) {
                    alert('Please select different microphones for left and right.');
                    return;
                }

                audioContext = new AudioContext();  // Omit sampleRate for iOS compatibility (defaults to 48000 Hz on Safari iOS)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                // Get streams for each selected microphone.
                const stream1 = await getMicStream(leftId);
                const stream2 = await getMicStream(rightId);

                // Create audio source nodes from each stream.
                const source1 = audioContext.createMediaStreamSource(stream1);
                const source2 = audioContext.createMediaStreamSource(stream2);

                // Create a ChannelMergerNode to combine the streams.
                const merger = audioContext.createChannelMerger(2); // Merge to 2 channels.
                
                // Connect each microphone source to a specific channel on the merger.
                source1.connect(merger, 0, 0); // Connect left mic to the first channel (index 0).
                source2.connect(merger, 0, 1); // Connect right mic to the second channel (index 1).

                // Connect the merged audio to the destination (e.g., speakers).
                // This allows you to hear the combined audio.
                merger.connect(audioContext.destination);

                // Create a destination stream for further processing.
                const destination = audioContext.createMediaStreamDestination();
                merger.connect(destination);
                
                console.log('Combined mic stream:', destination.stream);

                const workletCode = `
                    // Simple Complex number class
                    class Complex {
                        constructor(re = 0, im = 0) {
                            this.re = re;
                            this.im = im;
                        }
                        mul(other) {
                            return new Complex(
                                this.re * other.re - this.im * other.im,
                                this.re * other.im + this.im * other.re
                            );
                        }
                        conj() {
                            return new Complex(this.re, -this.im);
                        }
                        mag() {
                            return Math.sqrt(this.re * this.re + this.im * this.im);
                        }
                        add(other) {
                            return new Complex(this.re + other.re, this.im + other.im);
                        }
                        sub(other) {
                            return new Complex(this.re - other.re, this.im - other.im);
                        }
                    }

                    // Bit reversal permutation
                    function bitReverse(n, bits) {
                        let rev = 0;
                        for (let i = 0; i < bits; i++) {
                            if (n & (1 << i)) {
                                rev |= (1 << (bits - 1 - i));
                            }
                        }
                        return rev;
                    }

                    // Cooley-Tukey radix-2 FFT
                    function fft(signal, inverse = false) {
                        const N = signal.length;
                        const bits = Math.log2(N);
                        let out = new Array(N);
                        for (let i = 0; i < N; i++) {
                            out[bitReverse(i, bits)] = new Complex(signal[i], 0);
                        }
                        for (let size = 2; size <= N; size *= 2) {
                            const half = size / 2;
                            const step = Math.PI / half * (inverse ? -1 : 1);
                            for (let i = 0; i < N; i += size) {
                                let w = new Complex(1, 0);
                                const ws = Math.sin(step);
                                const wc = Math.cos(step);
                                for (let j = 0; j < half; j++) {
                                    const u = out[i + j];
                                    const v = out[i + j + half].mul(w);
                                    out[i + j] = u.add(v);
                                    out[i + j + half] = u.sub(v);
                                    w = new Complex(w.re * wc - w.im * ws, w.re * ws + w.im * wc);
                                }
                            }
                        }
                        if (inverse) {
                            const invN = 1 / N;
                            for (let i = 0; i < N; i++) {
                                out[i].re *= invN;
                                out[i].im *= invN;
                            }
                        }
                        return out;
                    }

                    class SoundLocalizerProcessor extends AudioWorkletProcessor {
                        constructor() {
                            super();
                            this.port.onmessage = (e) => {
                                if (e.data.type === 'update-d') {
                                    this.d = e.data.d;
                                }
                            };
                            // Compute biquad coefficients dynamically based on sample rate (highpass to filter low freq noise)
                            const Fc = 80;  // Cutoff frequency in Hz
                            const Q = 0.707;  // Butterworth Q
                            const Fs = sampleRate;
                            const K = Math.tan(Math.PI * Fc / Fs);
                            const norm = 1 / (1 + K / Q + K * K);
                            const b0 = 1 * norm;
                            this.b0 = b0;
                            this.b1 = -2 * b0;
                            this.b2 = b0;
                            this.a1 = 2 * (K * K - 1) * norm;
                            this.a2 = (1 - K / Q + K * K) * norm;

                            this.leftFilter = { x1: 0, x2: 0, y1: 0, y2: 0 };
                            this.rightFilter = { x1: 0, x2: 0, y1: 0, y2: 0 };
                            this.windowSize = 1024;
                            this.maxLag = 50;
                            this.leftBuf = new Float32Array(this.windowSize);
                            this.rightBuf = new Float32Array(this.windowSize);
                            this.writePos = 0;
                            this.d = 0.17;
                        }

                        process(inputs, outputs, parameters) {
                            const input = inputs[0];
                            if (!input || input.length < 2) {
                                return true;
                            }
                            const leftInput = input[0];
                            const rightInput = input[1];

                            for (let i = 0; i < leftInput.length; i++) {
                                // Filter left channel (biquad highpass)
                                let x = leftInput[i];
                                let left_y = (
                                    this.b0 * x +
                                    this.b1 * this.leftFilter.x1 +
                                    this.b2 * this.leftFilter.x2 -
                                    this.a1 * this.leftFilter.y1 -
                                    this.a2 * this.leftFilter.y2
                                );
                                this.leftFilter.x2 = this.leftFilter.x1;
                                this.leftFilter.x1 = x;
                                this.leftFilter.y2 = this.leftFilter.y1;
                                this.leftFilter.y1 = left_y;

                                // Filter right channel (biquad highpass)
                                x = rightInput[i];
                                let right_y = (
                                    this.b0 * x +
                                    this.b1 * this.rightFilter.x1 +
                                    this.b2 * this.rightFilter.x2 -
                                    this.a1 * this.rightFilter.y1 -
                                    this.a2 * this.rightFilter.y2
                                );
                                this.rightFilter.x2 = this.rightFilter.x1;
                                this.rightFilter.x1 = x;
                                this.rightFilter.y2 = this.rightFilter.y1;
                                this.rightFilter.y1 = right_y;

                                // Store filtered samples in buffers
                                this.leftBuf[this.writePos] = left_y;
                                this.rightBuf[this.writePos] = right_y;
                                this.writePos++;

                                // Compute correlation and RMS when buffer is full
                                if (this.writePos >= this.windowSize) {
                                    // Frequency domain correlation
                                    const fftLeft = fft(Array.from(this.leftBuf));
                                    const fftRight = fft(Array.from(this.rightBuf));
                                    const corrFreq = new Array(this.windowSize);
                                    for (let k = 0; k < this.windowSize; k++) {
                                        corrFreq[k] = fftLeft[k].mul(fftRight[k].conj());
                                    }
                                    const corrTime = fft(corrFreq, true);
                                    let maxCorr = -Infinity;
                                    let bestLag = 0;
                                    for (let lag = -this.maxLag; lag <= this.maxLag; lag++) {
                                        const idx = (this.windowSize + lag) % this.windowSize;
                                        const corr = corrTime[idx].mag();
                                        if (corr > maxCorr) {
                                            maxCorr = corr;
                                            bestLag = lag;
                                        }
                                    }

                                    // Compute RMS for left and right
                                    let sumL = 0;
                                    let sumR = 0;
                                    for (let j = 0; j < this.windowSize; j++) {
                                        sumL += this.leftBuf[j] * this.leftBuf[j];
                                        sumR += this.rightBuf[j] * this.rightBuf[j];
                                    }
                                    let leftRMS = Math.sqrt(sumL / this.windowSize);
                                    let rightRMS = Math.sqrt(sumR / this.windowSize);

                                    // Estimate angle (ITD approximation, clamped)
                                    let tau = bestLag / sampleRate;
                                    let c = 343;  // Speed of sound m/s
                                    let maxTau = this.d / c;
                                    if (Math.abs(tau) > maxTau) {
                                        tau = Math.sign(tau) * maxTau;
                                    }
                                    let theta = Math.asin(c * tau / this.d) * (180 / Math.PI);

                                    this.port.postMessage({ 
                                        angle: theta, 
                                        leftRMS: leftRMS, 
                                        rightRMS: rightRMS 
                                    });

                                    // Reset buffer
                                    this.writePos = 0;
                                }
                            }

                            // Passthrough to output (optional)
                            for (let channel = 0; channel < outputs[0].length; channel++) {
                                outputs[0][channel].set(input[channel]);
                            }

                            return true;
                        }
                    }

                    registerProcessor('sound-localizer', SoundLocalizerProcessor);
                `;

                const workletBlob = new Blob([workletCode], { type: 'application/javascript' });
                const workletUrl = URL.createObjectURL(workletBlob);
                await audioContext.audioWorklet.addModule(workletUrl);

                const mergedSource = audioContext.createMediaStreamSource(destination.stream);
                processor = new AudioWorkletNode(audioContext, 'sound-localizer');
                processor.port.onmessage = (event) => {
                    angle = event.data.angle;
                    leftHistory.push(event.data.leftRMS || 0);
                    if (leftHistory.length > maxHistory) {
                        leftHistory.shift();
                    }
                    rightHistory.push(event.data.rightRMS || 0);
                    if (rightHistory.length > maxHistory) {
                        rightHistory.shift();
                    }
                    draw();
                };
                mergedSource.connect(processor).connect(audioContext.destination);  // Connect to speakers if desired

                // Initial distance update
                updateMicDistance();
            } catch (error) {
                console.error('Error starting audio:', error);
                alert('Failed to start audio. Ensure microphone permissions and stereo input support. On iOS Safari, ensure iOS 14.5+ and user gesture.');
            }
        }

        function draw() {
            const dpr = window.devicePixelRatio || 1;
            const width = canvas.width / dpr;
            const height = canvas.height / dpr;
            ctx.clearRect(0, 0, width, height);

            const headCenterY = height * 0.3;
            ctx.save();
            ctx.translate(width / 2, headCenterY);

            // Draw head (circle)
            ctx.beginPath();
            ctx.arc(0, 0, 50, 0, 2 * Math.PI);
            ctx.strokeStyle = 'black';
            ctx.lineWidth = 2;
            ctx.stroke();

            // Draw baseline between mics (dashed)
            ctx.setLineDash([5, 5]);
            ctx.strokeStyle = 'gray';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(mics[0].x, mics[0].y);
            ctx.lineTo(mics[1].x, mics[1].y);
            ctx.stroke();
            ctx.setLineDash([]);

            // Draw microphone icons
            ctx.fillStyle = 'blue';
            mics.forEach(mic => {
                ctx.beginPath();
                ctx.arc(mic.x, mic.y, micRadius, 0, 2 * Math.PI);
                ctx.fill();
                ctx.fillStyle = 'white';
                ctx.font = '12px sans-serif';
                ctx.textAlign = 'left';
                ctx.textBaseline = 'middle';
                ctx.fillText(mic.label, mic.x + 8, mic.y);
                ctx.fillStyle = 'blue';
            });

            // Draw sound source direction (line from head center)
            if (angle !== undefined && !isNaN(angle)) {
                const rad = angle * (Math.PI / 180);
                const length = 100;
                ctx.beginPath();
                ctx.moveTo(0, 0);
                ctx.lineTo(length * Math.cos(rad), length * Math.sin(rad));
                ctx.strokeStyle = 'red';
                ctx.lineWidth = 3;
                ctx.stroke();
            }

            ctx.restore();

            // Draw RMS line chart in bottom (moving ticker)
            const numPoints = leftHistory.length;
            if (numPoints > 0) {
                const chartTop = height * 0.65;
                const chartBottom = height;
                const chartH = chartBottom - chartTop;
                const chartScaleX = (width - 1) / Math.max(1, numPoints - 1);

                // Left RMS (blue)
                ctx.strokeStyle = 'blue';
                ctx.lineWidth = 1;
                ctx.beginPath();
                for (let i = 0; i < numPoints; i++) {
                    const x = i * chartScaleX;
                    const rmsVal = Math.max(0, Math.min(1, leftHistory[i]));  // Clamp 0-1
                    const y = chartBottom - (rmsVal * chartH);
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                }
                ctx.stroke();

                // Right RMS (green)
                ctx.strokeStyle = 'green';
                ctx.beginPath();
                for (let i = 0; i < numPoints; i++) {
                    const x = i * chartScaleX;
                    const rmsVal = Math.max(0, Math.min(1, rightHistory[i]));  // Clamp 0-1
                    const y = chartBottom - (rmsVal * chartH);
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                }
                ctx.stroke();

                // Optional: draw baseline
                ctx.strokeStyle = 'gray';
                ctx.lineWidth = 0.5;
                ctx.beginPath();
                ctx.moveTo(0, chartBottom);
                ctx.lineTo(width - 1, chartBottom);
                ctx.stroke();
            }
        }
    </script>
</body>
</html>
```​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​